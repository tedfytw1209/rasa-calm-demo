recipe: default.v1
language: en
pipeline:
- name: LLMBasedRouter
  calm_entry:
    sticky: "handles everything else, including finance, doctor appointments and pizza orders"
  nlu_entry:
    sticky: "handles only health advice, hotel reservations, restaurant bookings, and target trail emulation"
    non_sticky: "handles chitchat"
- name: WhitespaceTokenizer
- name: CountVectorsFeaturizer
- name: CountVectorsFeaturizer
  analyzer: char_wb
  min_ngram: 1
  max_ngram: 4
- name: LogisticRegressionClassifier
  max_iter: 100
  solver: lbfgs
  tol: 0.0001
  random_state: 42
  ranking_length: 10
- name: CRFEntityExtractor
- name: DucklingEntityExtractor
  url: "http://localhost:8000"
  dimensions: [ "time", "number" ]
  timezone: "Europe/Berlin"
  timeout: 3
- name: NLUCommandAdapter
- name: CompactLLMCommandGenerator
  minimize_num_calls: False
  llm:
    model_group: openai-direct-gpt-4o

policies:
- name: RulePolicy
- name: FlowPolicy
- name: EnterpriseSearchPolicy
  use_generative_llm: true         # RAG (generative) mode, default but explicit
  vector_store:
    type: faiss                    # or "qdrant" / "milvus"
    source: "./docs"               # directory with your concept docs (Faiss)
  llm:
    # use your model group or direct model
    model_group: "openai-direct-gpt-4o"
  embedding:
    model_group: "openai-embeddings"
  prompt_template: "prompts/concept-explainer-rag.jinja2"
  citation_enabled: false          # your Concept Explainer doesnâ€™t need citations
  max_messages_in_query: 1         # only the last user question is enough
  max_history: 1

assistant_id: 20240418-073244-narrow-archive
